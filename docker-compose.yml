services:
  llm-enrichment-api:
    build: .
    container_name: llm_enrichment_api
    env_file:
      - .env
    ports:
      - "8000:8000"
    restart: unless-stopped
    environment:
      - LLM_PROVIDER=ollama
      - LLM_MODEL=llama3
    volumes:
      - /var/ossec/logs/alerts:/var/ossec/logs/alerts:ro
      - ./logs:/app/logs
